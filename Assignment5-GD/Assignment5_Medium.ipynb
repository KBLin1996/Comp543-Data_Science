{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f3ad63",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "464ddf40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e0a7b7054442d2acd3188ca7f6c708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>5</td><td>application_1637371168339_0006</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-86-104.ec2.internal:20888/proxy/application_1637371168339_0006/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-92-164.ec2.internal:8042/node/containerlogs/container_1637371168339_0006_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 1\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# load up the small dataset\n",
    "corpus = sc.textFile(\"s3://chrisjermainebucket/comp330_A5/TestingDataOneLinePerDoc.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa8d4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1a41375fb341cb8a6eeb6618aafe3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# each entry in validLines will be a line from the text file\n",
    "validLines = corpus.filter(lambda x: 'id' in x)\n",
    "# now we transform it into a bunch of (docID, text) pairs\n",
    "keyAndText = validLines.map(\n",
    "    lambda x: (x[x.index('id=\"') + 4:x.index('\" url=')], x[x.index('\">') + 2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77bb27a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7a3bb8d8e44da588d96b6069737aa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now we split the text in each (docID, text) pair into a list of words\n",
    "# after this, we have a data set with (docID, [\"word1\", \"word2\", \"word3\", ...])\n",
    "# we have a bit of fancy regular expression stuff here to make sure that we do not\n",
    "# die on some of the documents\n",
    "regex = re.compile('[^a-zA-Z]')\n",
    "keyAndListOfWords = keyAndText.map(\n",
    "    lambda x: (str(x[0]), regex.sub(' ', x[1]).lower().split()))\n",
    "\n",
    "# now get the top 20,000 words... first change (docID, [\"word1\", \"word2\", \"word3\", ...])\n",
    "# to (\"word1\", 1) (\"word2\", 1)...\n",
    "allWords = keyAndListOfWords.flatMap(lambda x: ((j, 1) for j in x[1]))\n",
    "\n",
    "# now, count all of the words, giving us (\"word1\", 1433), (\"word2\", 3423423), etc.\n",
    "allCounts = allWords.reduceByKey(lambda a, b: a + b)\n",
    "\n",
    "# and get the top 20,000 words in a local array\n",
    "# each entry is a (\"word1\", count) pair\n",
    "topWords = allCounts.top(20000, lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc48d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b253ab89997142aaa8fa2c87e499eaed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applicant: 604\n",
      "and: 2\n",
      "attack: 515\n",
      "protein: 3683\n",
      "car: 635"
     ]
    }
   ],
   "source": [
    "# and we'll create a RDD that has a bunch of (word, dictNum) pairs\n",
    "# start by creating an RDD that has the number 0 thru 20000\n",
    "# 20000 is the number of words that will be in our dictionary\n",
    "twentyK = sc.parallelize(range(20000))\n",
    "\n",
    "# now, we transform (0), (1), (2), ... to (\"mostcommonword\", 0) (\"nextmostcommon\", 1), ...\n",
    "# the number will be the spot in the dictionary used to tell us where the word is located\n",
    "# A bunch of (word, posInDictionary) pairs\n",
    "dictionary = twentyK.map(lambda x: (topWords[x][0], x))\n",
    "\n",
    "# Collect the Rdd to a Dict\n",
    "localDict = dictionary.collectAsMap()\n",
    "for inputWord in [\"applicant\", \"and\", \"attack\", \"protein\", \"car\"]:\n",
    "    if inputWord in localDict:\n",
    "        print(f'{inputWord}: {localDict[inputWord]}')\n",
    "    else:\n",
    "        print(f'{inputWord}: -1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05600ae",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b89c635f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16e446ad52ac41dc8b1add9d51430375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Task 2\n",
    "import math\n",
    "\n",
    "# A bunch of (word, docID) pairs\n",
    "wordDictPair = keyAndListOfWords.flatMap(lambda x: ((j, x[0]) for j in x[1]))\n",
    "# Join the two RDDs, you'll have a bunch of (word, (docID, posInDictionary)) pairs\n",
    "wordPair = wordDictPair.join(dictionary)\n",
    "\n",
    "# Get a bunch of (docid, (listOfAllDictonaryPos)) pairs\n",
    "docIDIdxPair = wordPair.map(lambda x: (x[1][0], x[1][1]))\n",
    "docIDAllIdxPair = docIDIdxPair.groupByKey()\n",
    "docIDAllIdxList = docIDAllIdxPair.map(lambda x: (x[0], list(x[1])))\n",
    "\n",
    "\n",
    "# Then finally, you will write a map () that will take that RDD and convert into the listOfAllDictonary\n",
    "def transformNP(idxList):\n",
    "    array = np.zeros(20000)\n",
    "    for i in idxList:\n",
    "        array[i] += 1\n",
    "    return array\n",
    "\n",
    "\n",
    "result = docIDAllIdxList.map(lambda x: (x[0], transformNP(x[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3dbcf009",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5afb819673a4109878277f9b7de6e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def findWord(wordList):\n",
    "    arr = np.zeros(20000)\n",
    "    for idx, i in enumerate(wordList):\n",
    "        if i > 0:\n",
    "            arr[idx] += 1\n",
    "    return arr\n",
    "\n",
    "\n",
    "# IDF\n",
    "def IDF(result):\n",
    "    cnt = 0\n",
    "    val = result.map(lambda x: (\"key\", findWord(x[1])))\n",
    "    finalList = val.reduceByKey(lambda a, b: a + b)\n",
    "    return finalList\n",
    "\n",
    "\n",
    "# Calculate IDF values\n",
    "size = result.count()\n",
    "IDFList = IDF(result)\n",
    "IDFArr = np.array(IDFList.lookup(\"key\"))\n",
    "IDFArr = np.log(size / IDFArr)\n",
    "\n",
    "\n",
    "# TF-IDF\n",
    "def TFIDF(arrCnt):\n",
    "    TFArr = arrCnt / arrCnt.sum()\n",
    "    finalResult = np.multiply(TFArr, IDFArr)\n",
    "    return finalResult\n",
    "\n",
    "\n",
    "def predictLabel(inputStr):\n",
    "    regex = re.compile('[^a-zA-Z]')\n",
    "\n",
    "    # Input string to a bunch of words\n",
    "    words = regex.sub(' ', inputStr).lower().split()\n",
    "    wordArr = np.zeros(20000)\n",
    "\n",
    "    for word in words:\n",
    "        if word in localDict.keys():\n",
    "            wordArr[localDict[word]] += 1\n",
    "    inputTFIDF = TFIDF(wordArr)\n",
    "    mean = np.mean(inputTFIDF)\n",
    "\n",
    "    return inputTFIDF\n",
    "\n",
    "\n",
    "# TFIDF for all dictionaries\n",
    "trainingInfo = keyAndText.map(lambda x: (x[0], predictLabel(x[1])))\n",
    "Data = keyAndText.map(lambda x:\n",
    "                      (1 if x[0][0:2] == \"AU\" else 0, predictLabel(x[1])))\n",
    "trainingData = Data.map(lambda x: (x[0], x[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b427b29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886959ad250144f7ba1f1d2d5183ce84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meanVec = trainingData.map(lambda x: (\"key\", x[1]))\n",
    "meanVec = meanVec.reduceByKey(lambda a, b: a + b)\n",
    "meanVec = meanVec.map(lambda x: x[1])\n",
    "mean = meanVec.collect()[0] / size\n",
    "\n",
    "varVec = trainingData.map(lambda x: (\"key\", 10000 * np.square(x[1] - mean)))\n",
    "varVec = varVec.reduceByKey(lambda a, b: a + b)\n",
    "varVec = varVec.map(lambda x: x[1])\n",
    "var = np.sqrt(varVec.collect()[0] / size)\n",
    "var[var == 0] = 1\n",
    "training = trainingData.map(lambda x: (x[0], (x[1] - mean) / var))\n",
    "training = training.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3151b074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e18a8c742e0e45849c0cb4e8af7b4301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, array([ 0.00522844,  0.00266889, -0.00711476, ..., -0.00033807,\n",
      "       -0.00024124, -0.00058526]))]"
     ]
    }
   ],
   "source": [
    "training.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0d14bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d453fe447514eeabeda93c41ed49dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x is the data set\n",
    "# y is the labels\n",
    "# w is the current set of weights\n",
    "# c is the weight of the slack variables\n",
    "\n",
    "\n",
    "# Evaluates and returns the gradient\n",
    "def gradient(train, w, c):\n",
    "    l2 = np.linalg.norm(w, 2)\n",
    "    grad_per_row = train.map(lambda x: -1 * x[0] * x[1] + x[1] * (np.exp(\n",
    "        np.dot(x[1], w)) / (1 + np.exp(np.dot(x[1], w)))) + c * w)\n",
    "    acc = np.zeros(20000)\n",
    "    grad = grad_per_row.fold(acc, lambda a, b: a + b)\n",
    "    print(f\"Gradient: {grad}\")\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6be9b897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f69dade4fd42f590824c0af35bea71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from operator import add\n",
    "\n",
    "# x is the data set\n",
    "# y is the labels\n",
    "# w is the current set of weights\n",
    "# c is the weight of the slack variables\n",
    "\n",
    "\n",
    "# Evaluates the loss function and returns the loss\n",
    "def f(train, w, c):\n",
    "    l2 = np.linalg.norm(w, 2)\n",
    "    loss_per_row = train.map(lambda x: (\"key\", (-1 * x[0] * np.dot(x[\n",
    "        1], w)) + np.log(1 + np.exp(np.dot(x[1], w))) + c * l2 * l2))\n",
    "    loss = loss_per_row.reduceByKey(add).collect()\n",
    "    loss = loss[0][1]\n",
    "    print(f\"Loss: {loss}\")\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b53224a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c9c47000a94aba87aaf602917811f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# performs gradient descent optimization, returns the learned set of weights\n",
    "# uses the bold driver to set the learning rate\n",
    "#\n",
    "# x is the data set\n",
    "# y is the labels\n",
    "# w is the current set of weights  to start with\n",
    "# c is the weight of the slack variable\n",
    "def gd_optimize(train, w, c):\n",
    "    rate = 0.001\n",
    "    w_last = w + np.full(20000, 1.0)\n",
    "    while (abs(f(train, w, c) - f(train, w_last, c))) > 10e-4:\n",
    "        w_last = w\n",
    "        w = w - rate * gradient(train, w, c)\n",
    "        if f(train, w, c) > f(train, w_last, c):\n",
    "            rate = rate * 0.5\n",
    "        else:\n",
    "            rate = rate * 1.1\n",
    "        print(f(train, w, c))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0390de78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715707c8453a4875bce814e53e0bc4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 50660.52066676006\n",
      "Loss: 3807375.7981457813\n",
      "Gradient: [  6.75506179  -4.67350353  17.22033921 ...   7.19821718  32.30789691\n",
      " -30.5685946 ]\n",
      "Loss: 37823.383275563174\n",
      "Loss: 50660.52066676006\n",
      "Loss: 37823.383275563174\n",
      "37823.383275563174\n",
      "Loss: 37823.383275563174\n",
      "Loss: 50660.52066676006\n",
      "Gradient: [  5.48837337  -3.76615553  13.86426689 ...   5.84556329  26.228065\n",
      " -24.82769315]\n",
      "Loss: 28607.2964142238\n",
      "Loss: 37823.383275563174\n",
      "Loss: 28607.296414223805\n",
      "28607.296414223805\n",
      "Loss: 28607.296414223805\n",
      "Loss: 37823.383275563174\n",
      "Gradient: [  4.35676578  -2.96317266  10.89303703 ...   4.63711184  20.79874147\n",
      " -19.69858582]\n",
      "Loss: 22301.3890598984\n",
      "Loss: 28607.2964142238\n",
      "Loss: 22301.3890598984\n",
      "22301.3890598984\n",
      "Loss: 22301.3890598984\n",
      "Loss: 28607.296414223805\n",
      "Gradient: [  3.3690423   -2.26959178   8.32630727 ...   3.58250793  16.0627737\n",
      " -15.22211409]\n",
      "Loss: 18214.560072356155\n",
      "Loss: 22301.3890598984\n",
      "Loss: 18214.560072356155\n",
      "18214.560072356155\n",
      "Loss: 18214.560072356155\n",
      "Loss: 22301.3890598984\n",
      "Gradient: [  2.52921373  -1.6865667    6.16942564 ...   2.68617921  12.03948855\n",
      " -11.41700436]\n",
      "Loss: 15723.775978621336\n",
      "Loss: 18214.56007235616\n",
      "Loss: 15723.775978621336\n",
      "15723.775978621336\n",
      "Loss: 15723.775978621334\n",
      "Loss: 18214.560072356155\n",
      "Gradient: [ 1.83600218 -1.21121133  4.41264061 ...  1.94682188  8.72242342\n",
      " -8.27770195]\n",
      "Loss: 14308.242863886628\n",
      "Loss: 15723.775978621336\n",
      "Loss: 14308.242863886626\n",
      "14308.242863886626\n",
      "Loss: 14308.242863886626\n",
      "Loss: 15723.775978621334\n",
      "Gradient: [ 1.28274814 -0.83676393  3.03151618 ...  1.3573173   6.07900134\n",
      " -5.77402702]\n",
      "Loss: 13565.628209903569\n",
      "Loss: 14308.242863886628\n",
      "Loss: 13565.62820990357\n",
      "13565.62820990357\n",
      "Loss: 13565.62820990357\n",
      "Loss: 14308.242863886628\n",
      "Gradient: [ 0.85780167 -0.55309579  1.98868488 ...  0.90516215  4.05251755\n",
      " -3.85300105]\n",
      "Loss: 13210.345388252998\n",
      "Loss: 13565.62820990357\n",
      "Loss: 13210.345388252998\n",
      "13210.345388252998\n",
      "Loss: 13210.345388252998\n",
      "Loss: 13565.62820990357\n",
      "Gradient: [ 0.54541707 -0.3475436   1.23689777 ...  0.57343404  2.56652779\n",
      " -2.44293553]\n",
      "Loss: 13057.660590808371\n",
      "Loss: 13210.345388252998\n",
      "Loss: 13057.660590808373\n",
      "13057.660590808373\n",
      "Loss: 13057.660590808371\n",
      "Loss: 13210.345388252998\n",
      "Gradient: [ 0.32708847 -0.20599084  0.72311019 ...  0.34223034  1.5313486\n",
      " -1.45951902]\n",
      "Loss: 12999.850675927382\n",
      "Loss: 13057.660590808373\n",
      "Loss: 12999.850675927382\n",
      "12999.850675927382\n",
      "Loss: 12999.850675927382\n",
      "Loss: 13057.660590808371\n",
      "Gradient: [ 0.18317597 -0.11406974  0.39311415 ...  0.19042335  0.85195573\n",
      " -0.81324002]\n",
      "Loss: 12981.071069199008\n",
      "Loss: 12999.850675927382\n",
      "Loss: 12981.071069199008\n",
      "12981.071069199008\n",
      "Loss: 12981.071069199008\n",
      "Loss: 12999.850675927382\n",
      "Gradient: [ 0.09459702 -0.05831631  0.19605616 ...  0.0974919   0.43619832\n",
      " -0.41713254]\n",
      "Loss: 12976.043549407254\n",
      "Loss: 12981.071069199008\n",
      "Loss: 12976.043549407254\n",
      "12976.043549407254\n",
      "Loss: 12976.043549407252\n",
      "Loss: 12981.071069199008\n",
      "Gradient: [ 0.04432189 -0.02710454  0.08813134 ...  0.04514528  0.20205505\n",
      " -0.19364606]\n",
      "Loss: 12975.014324678696\n",
      "Loss: 12976.043549407254\n",
      "Loss: 12975.014324678696\n",
      "12975.014324678696\n",
      "Loss: 12975.014324678696\n",
      "Loss: 12976.043549407254\n",
      "Gradient: [ 0.01843354 -0.01122161  0.0348713  ...  0.01847551  0.08275496\n",
      " -0.07952464]\n",
      "Loss: 12974.883811354099\n",
      "Loss: 12975.014324678696\n",
      "Loss: 12974.883811354099\n",
      "12974.883811354099\n",
      "Loss: 12974.883811354099\n",
      "Loss: 12975.014324678696\n",
      "Gradient: [ 0.00659988 -0.00402197  0.01174568 ...  0.00646669  0.02901008\n",
      " -0.02797337]\n",
      "Loss: 12974.885960576132\n",
      "Loss: 12974.883811354099\n",
      "Loss: 12974.885960576132\n",
      "12974.885960576132\n",
      "Loss: 12974.885960576132\n",
      "Loss: 12974.883811354099\n",
      "Gradient: [ 0.00194281 -0.00119583  0.00320244 ...  0.00184187  0.0082866\n",
      " -0.00802724]\n",
      "Loss: 12974.888064858764\n",
      "Loss: 12974.885960576132\n",
      "Loss: 12974.888064858764\n",
      "12974.888064858764\n",
      "Loss: 12974.888064858764\n",
      "Loss: 12974.885960576132\n",
      "Gradient: [ 0.00125773 -0.00077719  0.00204207 ...  0.00118304  0.00532698\n",
      " -0.00516551]\n",
      "Loss: 12974.888835692784\n",
      "Loss: 12974.888064858764\n",
      "Loss: 12974.888835692784\n",
      "12974.888835692784\n",
      "Loss: 12974.888835692784\n",
      "Loss: 12974.888064858764"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "w = np.random.normal(0, 0.1, size=(20000))\n",
    "c = 0.01\n",
    "w = gd_optimize(training, w, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59f499d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34eac710488b4ce2b8b8936bea80ce9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['that', 'not', 'any', 'court', 'act', 'mr', 'evidence', 'decision', 'whether', 'tribunal', 'application', 'applicant', 'claim', 'matter', 'reasons', 'appeal', 'appellant', 'orders', 'relevant', 'ltd', 'sought', 'notice', 'circumstances', 'relation', 'hearing', 'proceedings', 'respondent', 'consider', 'matters', 'regard', 'proceeding', 'respondents', 'pty', 'judgment', 'satisfied', 'submissions', 'affidavit', 'magistrate', 'pursuant', 'fca', 'clr', 'hca', 'amp', 'discretion', 'fcr', 'alr', 'jurisdictional', 'relevantly', 'fcafc', 'gummow']"
     ]
    }
   ],
   "source": [
    "idx = np.argpartition(w, -50)[-50:]\n",
    "output = list()\n",
    "\n",
    "for key, value in localDict.items():\n",
    "    if value in idx:\n",
    "        output.append(key)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a599f4b7",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cce997bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76678573492d42118fcc971b16047b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Testing Data\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# load up the small dataset\n",
    "corpus = sc.textFile(\n",
    "    \"s3://chrisjermainebucket/comp330_A5/SmallTrainingDataOneLinePerDoc.txt\")\n",
    "# each entry in validLines will be a line from the text file\n",
    "validLines = corpus.filter(lambda x: 'id' in x)\n",
    "# now we transform it into a bunch of (docID, text) pairs\n",
    "keyAndText = validLines.map(\n",
    "    lambda x: (x[x.index('id=\"') + 4:x.index('\" url=')], x[x.index('\">') + 2:]))\n",
    "\n",
    "# TFIDF for all dictionaries\n",
    "testingData = keyAndText.map(\n",
    "    lambda x: (1 if x[0][0:2] == \"AU\" else 0, predictLabel(x[1])))\n",
    "testingData = testingData.map(lambda x: (x[0], x[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c6b95fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5817fa1bfb4e9f8dd5a6964fa0ec29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions using all of the data points in x\n",
    "# print ‘success’ or ‘failure’ depending on whether the\n",
    "# prediction is correct\n",
    "\n",
    "# x is the data set\n",
    "# y is the labels\n",
    "# w is the current set of weights\n",
    "\n",
    "\n",
    "def predict(x, y, w):\n",
    "    if ((np.dot(x, w) > 0.01) and (y == 1)):\n",
    "        # print(\"True Positive\")\n",
    "        return \"tp\"\n",
    "    elif ((np.dot(x, w) < 0.01) and (y == 0)):\n",
    "        # print(\"True Negative\")\n",
    "        return \"tn\"\n",
    "    elif ((np.dot(x, w) > 0.01) and (y == 0)):\n",
    "        # print(\"False Positive\")\n",
    "        return \"fp\"\n",
    "    elif ((np.dot(x, w) < 0.01) and (y == 1)):\n",
    "        # print(\"False Negative\")\n",
    "        return \"fn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64a17ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7ea6ade7ef4bce935e32e834cffad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = testingData.map(lambda x: predict(x[1], x[0], w)).collect()\n",
    "\n",
    "fpList = list()\n",
    "tp = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "for idx, i in enumerate(prediction):\n",
    "    if i == \"tp\":\n",
    "        tp += 1\n",
    "    elif i == \"tn\":\n",
    "        tn += 1\n",
    "    elif i == \"fp\":\n",
    "        fp += 1\n",
    "        fpList.append(idx)\n",
    "    elif i == \"fn\":\n",
    "        fn += 1\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "f1score = 2 * precision * recall / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46948461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f444452c8c14e4aabe657751c020bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 72\n",
      "TN: 3360\n",
      "FP: 8\n",
      "FN: 2\n",
      "3432 out of 3442 correct.\n",
      "Precision: 0.9\n",
      "Recall: 0.972972972972973\n",
      "F1 Score: 0.935064935064935"
     ]
    }
   ],
   "source": [
    "print(f'TP: {tp}')\n",
    "print(f'TN: {tn}')\n",
    "print(f'FP: {fp}')\n",
    "print(f'FN: {fn}')\n",
    "print(\"%d out of %d correct.\" % (tp + tn, len(prediction)))\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1score}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18071e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f604ef8c3d24c7ab1e19417b69f2801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103, 341, 512, 549, 771, 839, 1676, 3054]"
     ]
    }
   ],
   "source": [
    "print(fpList)\n",
    "checkFP = keyAndText.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f290d746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2b6b91a04fa4dbc93a8117edb6c79d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('35399712', ' Rainy Sky SA and others v Kookmin Bank  Rainy Sky SA and others v Kookmin Bank  is an English contract law case concerning interpretation of contracts. The Supreme Court confirmed the principle laid down in \"Wickman v Schuler\" that, if the words of a contract have ambiguous meanings, the court will interpret it in a manner that most accords with \"business common sense\". There is no requirement for a party to prove that the alternative interpretation is entirely unreasonable. Facts. Rainy Sky was one of five ship-owning firms that ordered vessels from Jinse Shipbuilding Co, a South Korean shipbuilder, at a cost of US$33,300,000 per ship. The payment was to be made in five equal installments. The contract between Rainy Sky and Jinse permitted Rainy Sky to rescind the contract if various events occurred (such as late delivery or inadequate performance of the vessel, or loss of the vessel before delivery). It also obliged Jinse to refund the payments if it became insolvent, although, in this case, the contract would not automatically be rescinded. Jinse were required to provide the buyers with a performance bond, guaranteeing the repayment of the buyer\\'s money. Jinse obtained such a bond from Kookmin Bank - however, the terms of the bond did not match exactly the terms of the contract, and the central issue in the court case was the interpretation of the bond. The bond stated (\"inter alia\"): \"Pursuant to the terms of the Contract, you [Rainy Sky are entitled, upon your rejection of the Vessel in accordance with the terms of the Contract, your termination, cancellation or rescission of the Contract or upon a Total Loss of the Vessel, to repayment of the pre-delivery instalments...\" \" ...we hereby ... undertake to pay to you ... all such sums due to you under the Contract...\" Rainy Sky had made two of the required payments when Jinse encountered financial difficulties and entered into an insolvency process. This triggered the requirement for it to repay the money, and, as it could not do this, Rainy Sky called on Kookmin Bank to honour the guarantee. Kookmin, however, claimed that it was under no obligation to make the payment, as the bond only covered \"rejection of the vessel\" and \"termination, cancellation or recission of the contract\", not the insolvency of Jinse. Judgement. In the Commercial Court, Simon J, in a summary judgement, ruled that the bond did cover Jinse\\'s obligation to repay on insolvency. He emphasised \"\"all\" such sums\" in paragraph 3, and stated that Kookmin\\'s construction \"has the surprising and uncommercial result that the Buyers would not be able to call on the Bond on the happening of the event which would be most likely to require the first class security.\" Kookmin appealed, and in the Court of Appeal, Patten LJ (with whom Thorpe LJ agreed) supported their interpretation. Patten LJ ruled that the word \"such\" in paragraph 3 could not be ignored, and that, while it was possible that it referred only to the \"pre-delivery installments\" mentioned in paragraph 2, as a matter of grammar, it was more likely (\"in any way evenly balanced\") that it referred to the sums defined in paragraph 2 as a whole (namely, those due on rejection, termination, cancellation, recission, or total loss). He stated that the alternative interpretation \"robs paragraph 2 of any purpose or effect.\" The critical issue was therefore whether or not Kookmin\\'s interpretation was commercially unreasonable. After citing earlier authorities (\"Wickman v Schuler\" [1974 AC 235, \"The Antaios\" AC 191 and \"Chartbrook v Persimmon\" [2009 UKHL 38), he ruled that, because Kookmin\\'s interpretation was not \"absurd or irrational\" or \"so extreme as to suggest that it was unintended\", merely unfavourable to Rainy Sky, it should be accepted. The alternative course would \"put us in real danger of substituting our own judgment of the commerciality of the transaction for that of those who were actually party to it.\" However, Sir Simon Tuckey delivered a dissenting judgement, in which he stated that Simon J\\'s first-instance view that Kookmin\\'s interpretation was \"surprising and uncommercial\" was a legitimate reason for rejecting that interpretation, and that the judgement therefore should not be overturned. The Supreme Court allowed Rainy Sky\\'s appeal. Lord Clarke delivered the judgement. Citing the case of \"Co-operative Wholesale Society Ltd v National Westminster Bank plc\" 1 EGLR 97, he accepted the principle that \"where the parties have used unambiguous language, the court must apply it\", no matter how commercially unreasonable the result. However, in cases of ambiguity, the court should choose the interpretation that is \"most consistent with business common sense\" - there is no obligation on the party contesting the interpretation to prove that it is so extreme that the parties could not have intended it in any circumstances, as Patten LJ\\'s test would imply. Referring to \"Barclays Bank plc v HHY Luxembourg SARL\" EWCA Civ 1248, he held that the correct test was stated by Longmore LJ in that case: \"If a clause is capable of two meanings, as on any view this clause is, it is quite possible that neither meaning will flout common sense. In such circumstances, it is much more appropriate to adopt the more, rather than the less, commercial construction.\" Consequences. Various commentators, such as Oliver Gayner and Cathryn Hopkins of Olswang\\'s and Thomas G. Heintzman of McCarthy Tétrault have suggested that parties to such cases may, as a result of this ruling, seek to introduce expert evidence on the precise degree of \"commercial reasonableness\" that a particular interpretation of a contract would imply.  </doc> ')"
     ]
    }
   ],
   "source": [
    "checkFP[549]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01841d02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
